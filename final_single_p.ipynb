{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "#from fbprophet import Prophet\n",
    "#from fbprophet.plot import plot_plotly, add_changepoints_to_plot\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "\n",
    "# from keras.optimizers import Adam\n",
    "import prophet\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "czech  = pd.read_csv('univariate_models/univariate_df_Czechia.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "eston  = pd.read_csv('univariate_models/univariate_df_Estonia.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "franc  = pd.read_csv('univariate_models/univariate_df_France.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "malay  = pd.read_csv('univariate_models/univariate_df_Malaysia.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "belgi  = pd.read_csv('univariate_models/univariate_df_Belgium.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "chile  = pd.read_csv('univariate_models/univariate_df_Chile.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "irela  = pd.read_csv('univariate_models/univariate_df_Ireland.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "israe  = pd.read_csv('univariate_models/univariate_df_Israel.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "italy  = pd.read_csv('univariate_models/univariate_df_Italy.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "us  = pd.read_csv('univariate_models/univariate_df_United_States.csv',usecols=[1,2],  parse_dates=[0]).reset_index(drop=True)\n",
    "\n",
    "#sort index\n",
    "for x in [czech, eston, franc, malay,belgi, chile, irela, israe, italy, us]:\n",
    "    x = x.sort_index()\n",
    "train_size = int(len(czech) * 0.8)\n",
    "czech_train, czech_test = czech[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), czech[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "eston_train, eston_test = eston[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), eston[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "franc_train, franc_test = franc[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), franc[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "malay_train, malay_test = malay[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), malay[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "belgi_train, belgi_test = belgi[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), belgi[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "chile_train, chile_test = chile[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), chile[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "irela_train, irela_test = irela[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), irela[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "israe_train, israe_test = israe[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), israe[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "italy_train, italy_test = italy[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), italy[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "us_train, us_test = us[0:train_size].rename(columns={'date': 'ds', 'new_deaths': 'y'}), us[train_size:].rename(columns={'date': 'ds', 'new_deaths': 'y'})\n",
    "czech_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true, y_pred):\n",
    "    naive_forecast = y_true[:-1]\n",
    "    y_true_insample = y_true[1:]\n",
    "    insample_error = np.abs(y_true_insample - naive_forecast)\n",
    "    # Calculate the forecast errors\n",
    "    forecast_error = np.abs(y_true - y_pred)\n",
    "    # Calculate the MASE\n",
    "    mase = np.mean(forecast_error) / np.mean(insample_error)\n",
    "    return mase\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['Model', 'MAE', 'MASE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = czech_train, czech_test\n",
    "model_baseline = Prophet()\n",
    "model_baseline.fit(train)\n",
    "future_baseline = model_baseline.make_future_dataframe(periods=41) # periods are 41"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
